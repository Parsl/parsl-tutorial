{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsl WorkQueueExecutor tutorial\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"./figures/parsl-logo.png\" width=\"600\" /> </td> \n",
    "<td> <img src=\"./figures/WorkQueueLogoSmall.png\" width=\"430\" /> </td> \n",
    "</tr></table> \n",
    "\n",
    "    \n",
    "## WorkQueue installation\n",
    "\n",
    "To use WQEX in Parsl, please install the full CCTools software package within an appropriate Anaconda or Miniconda environment.\n",
    "\n",
    "1. pip install parsl\n",
    "2. conda install -y -c conda-forge ndcctools\n",
    "\n",
    "\n",
    "## Fine-grained resource management\n",
    "\n",
    "In this tutorial we present three typical use cases of WorkQueueExecutor (**WQEX**) in Parsl, including the **default**, **autolabel** and **per-task resource specification**.\n",
    "\n",
    "1. **Default** is suitable for use cases where the apps need to utilize the resource of the entire node. For example, an app itself already does some parallelism internally.\n",
    "2. **Autolabel** is to enable Work Queue to automatically figure out the resource needed for every task. To do so, Work Queue assigns all the resource of a worker to profile the first few number of tasks for a category, and then monitors their resource usages. Based on the profiling, Work Queue automatically assigns the remaining tasks of the category to use the computing resource efficiently.\n",
    "3. **Per-task resource specification** allows a user to specify the resource of an app.\n",
    "\n",
    "We will go through each of these use cases in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for this notebook\n",
    "from parsl.config import Config\n",
    "from parsl.executors import WorkQueueExecutor\n",
    "from parsl.providers import LocalProvider\n",
    "\n",
    "import parsl\n",
    "from parsl.app.app import python_app\n",
    "\n",
    "import time\n",
    "import multiprocessing\n",
    "import glob\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default configuration\n",
    "\n",
    "Now we define an initial WQEX configuration. Like the configuration of other executors (e.g. HTEX), we need to define a provider for WQEX. This will automatically launch **ONE** WorkQueue worker on each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default configuration of WQEX\n",
    "config = Config(\n",
    "    executors=[\n",
    "        WorkQueueExecutor(port=50055,\n",
    "                          provider=LocalProvider()\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "dfk = parsl.load(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define an simple sleeper app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app\n",
    "def sleeper(dur=1):\n",
    "    \"\"\" \n",
    "    An app that sleeps for certain duration\n",
    "    \"\"\"\n",
    "    import time\n",
    "    time.sleep(dur)\n",
    "    return dur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we run the apps. By default, the autolabeling is not enabled. So each worker can only run one task at a time and you can see that the following `sleeper` apps are essentially run in serial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Tasks finished in 19.350595474243164\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tasks = [sleeper() for i in range(10)]\n",
    "res = [t.result() for t in tasks]\n",
    "print(res)\n",
    "print(f\"Tasks finished in {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see below, there are multiple cores on the node. So this default mode is only suitable for apps that need to use the entire computing node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up the loaded Parsl WQEX default config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfk.cleanup()\n",
    "parsl.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autolabel\n",
    "\n",
    "Let us enable the autolabeling in this new configuration. To enable autolabeling, we just need to set `autolabel=True`. Here we also set `autocateogory=True` so that WorkQueue categorizes an app based on its function name. By default, we have `autocateogory=False`, which means that WQEX categorizes all Parsl apps into one category, `parsl-default`. This is not the best practise since different apps may present various resource patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration with autolabel and autocategory enabled\n",
    "config = Config(\n",
    "    executors=[\n",
    "        WorkQueueExecutor(port=50055,\n",
    "                          autolabel=True,\n",
    "                          autocategory=True,\n",
    "                          provider=LocalProvider()\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "dfk = parsl.load(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define an app called `mp_task` that can stress multiple cores. In this app, we use the `multiprocessing` module to implement it. We then run 5 `mp_task` tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Done with 2 cores', 'Done with 2 cores', 'Done with 2 cores', 'Done with 2 cores', 'Done with 2 cores']\n",
      "Tasks finished in 7.120572328567505\n"
     ]
    }
   ],
   "source": [
    "@python_app\n",
    "def mp_task(cores=2):\n",
    "    \"\"\"\n",
    "    An app that use multiprocessing to mimic an app that uses multiple cores\n",
    "    \"\"\"\n",
    "    from multiprocessing import Process, Pool\n",
    "    import time\n",
    "    def stress(dur=2):\n",
    "        start = time.time()\n",
    "        while time.time() - start < dur:\n",
    "            continue\n",
    "    \n",
    "    processes = []\n",
    "    for i in range(cores):\n",
    "        p = Process(target=stress, args=(2,))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    return f'Done with {cores} cores'\n",
    "\n",
    "\n",
    "# Submit 5 mp_task app\n",
    "start = time.time()\n",
    "tasks = []\n",
    "for i in range(5):\n",
    "    fut = mp_task()\n",
    "    tasks.append(fut)\n",
    "res = [t.result() for t in tasks]\n",
    "print(res)\n",
    "print(f\"Tasks finished in {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WorkQueue automatically monitors the resource usage of this category (based on the function name of app). Let us define a function to parse the logs to get the resource requirement inferred by WorkQueue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_logs():\n",
    "    \"\"\"\n",
    "    Parse the resource assignment of Work Queue from the runinfo logs\n",
    "    \"\"\"\n",
    "    dirs = glob.glob(\"runinfo/*\")\n",
    "    log = \"{}/WorkQueueExecutor/transaction_log\".format(sorted(dirs)[-1])\n",
    "    with open(log) as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    resources = ['task_id', 'task_type', 'cores', 'memory', 'disk']\n",
    "    df = pd.DataFrame(columns=resources)\n",
    "    task_ids = {}\n",
    "    for line in lines:\n",
    "        if \"WAITING\" in line and \"WAITING_RETRIEVAL\" not in line and 'taskid' not in line:\n",
    "                line = line.split()\n",
    "                task_id = line[3]\n",
    "                task_category = line[5]\n",
    "                task_ids[task_id] = task_category\n",
    "\n",
    "        # timestamp master-pid TASK id (continue next line)\n",
    "        # DONE SUCCESS exit-code exceeded measured\n",
    "        if \"RUNNING\" in line and 'taskid' not in line:\n",
    "            line = line.split()\n",
    "            task_id = line[3]\n",
    "            s = json.loads(line[-1])\n",
    "\n",
    "            # append the new resources to the panda's data frame.\n",
    "            # Resources are represented in a json array as\n",
    "            # [value, \"unit\", such as [1000, \"MB\"],\n",
    "            # so we only take the first element of the array:\n",
    "            df.loc[len(df)] = [task_id, task_ids[task_id]] + list(float(s[r][0]) for r in resources[2:])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the resource for each `mp_task` task assigned by WorkQueue. \n",
    "\n",
    "As we see, the first `mp_task` task uses 56 cores, 257GB memory, and 112GB disk. This is because WorkQueue assigns all the resource on a compute node to the task, in order to profile the resource utilization for the first task. After that, WorkQueue updates the resource for this category (based on function name) accordingly, and thus the later tasks use only 2 cores, 57MB memory, and 2MB disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>task_type</th>\n",
       "      <th>cores</th>\n",
       "      <th>memory</th>\n",
       "      <th>disk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>mp_task</td>\n",
       "      <td>56.0</td>\n",
       "      <td>257036.0</td>\n",
       "      <td>118338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>mp_task</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>mp_task</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>mp_task</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>mp_task</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  task_id task_type  cores    memory      disk\n",
       "0       1   mp_task   56.0  257036.0  118338.0\n",
       "1       2   mp_task    2.0      57.0       2.0\n",
       "2       3   mp_task    2.0      57.0       2.0\n",
       "3       4   mp_task    2.0      57.0       2.0\n",
       "4       5   mp_task    2.0      57.0       2.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = parse_logs()\n",
    "df[df['task_type'] == 'mp_task'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-task resource specification\n",
    "\n",
    "Besides **autolabel**, WQEX supports a user to specify the resource requirement of a Parsl app by using a specific kwarg **parsl_resource_specification**. There are two ways you can specify the resource requirements for each app.\n",
    "\n",
    "### Declare resource requirements in the kwargs when you define an app\n",
    "This declaration is the default resource requirements for `mp_task_spec` app. Currently, WQEX supports specification of three types of resources: **cores, memory, and disk**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app\n",
    "def mp_task_spec(cores=2, parsl_resource_specification={'cores': 3, 'memory': 100, 'disk': 100}):\n",
    "    from multiprocessing import Process\n",
    "    import time\n",
    "    def stress(dur=2):\n",
    "        start = time.time()\n",
    "        while time.time() - start < dur:\n",
    "            continue\n",
    "    \n",
    "    processes = []\n",
    "    for i in range(cores):\n",
    "        p = Process(target=stress, args=(2,))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    return f'Done with {cores} cores'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we invoke an app without further specifying the resource requirements, WQEX allocates each invocation the default resource when we define the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Done with 2 cores', 'Done with 2 cores', 'Done with 2 cores']\n",
      "Tasks finished in 5.371891498565674\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tasks = []\n",
    "for i in range(3):\n",
    "    fut = mp_task_spec(cores=2)\n",
    "    tasks.append(fut)\n",
    "res = [t.result() for t in tasks]\n",
    "print(res)\n",
    "print(f\"Tasks finished in {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the resource for each `mp_task_spec` task assigned by WorkQueue. As we see, all invocations of `mp_task_spec` are allocated by the same resource, which is 3 cores, 100MB memory, and 100MB disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>task_type</th>\n",
       "      <th>cores</th>\n",
       "      <th>memory</th>\n",
       "      <th>disk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>mp_task_spec</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>mp_task_spec</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>mp_task_spec</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  task_id     task_type  cores  memory   disk\n",
       "5       6  mp_task_spec    3.0   100.0  100.0\n",
       "6       7  mp_task_spec    3.0   100.0  100.0\n",
       "7       8  mp_task_spec    3.0   100.0  100.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = parse_logs()\n",
    "df[df['task_type'] == 'mp_task_spec'].head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to using the default resource specification, we can also change the resource requirement when we invoke the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Done with 1 cores', 'Done with 2 cores', 'Done with 3 cores']\n",
      "Tasks finished in 5.375324249267578\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tasks = []\n",
    "for i in range(3):\n",
    "    # Vary the resource specification per invocation\n",
    "    fut = mp_task_spec(cores=i+1,\n",
    "                       parsl_resource_specification={'cores': i+1, 'memory': 100, 'disk': 100})\n",
    "    tasks.append(fut)\n",
    "res = [t.result() for t in tasks]\n",
    "print(res)\n",
    "print(f\"Tasks finished in {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the resource for each mp_task_spec task assigned by WorkQueue. As we see, all invocations of `mp_task_spec` use different resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>task_type</th>\n",
       "      <th>cores</th>\n",
       "      <th>memory</th>\n",
       "      <th>disk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>mp_task_spec</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>mp_task_spec</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>mp_task_spec</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   task_id     task_type  cores  memory   disk\n",
       "8        9  mp_task_spec    1.0   100.0  100.0\n",
       "9       10  mp_task_spec    2.0   100.0  100.0\n",
       "10      11  mp_task_spec    3.0   100.0  100.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = parse_logs()\n",
    "df[df['task_type'] == 'mp_task_spec'].tail(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth mentioning that any resource specification overrides what Work Queue **autolabel** mode infers.\n",
    "\n",
    "1. With autolabel **enabled**, we do not have to specify all three types of resources for an app. We can choose to specify some of them. For example, in the below, we only specify cores and memory, but autolabel automatically infers what is needed for disk and fill that gap.\n",
    "\n",
    "2. With autolabel **disabled**, if we do not specify all three types of resources, cores, memory, and disk, Work Queue alloates all the resource of a worker (i.e., a compute node) to run the app. This is not a proper configuration we should use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>task_type</th>\n",
       "      <th>cores</th>\n",
       "      <th>memory</th>\n",
       "      <th>disk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>mp_task_spec</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   task_id     task_type  cores  memory  disk\n",
       "11      12  mp_task_spec    2.0    60.0  50.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fut = mp_task_spec(cores=2, parsl_resource_specification={'cores': 2, 'disk': 50})\n",
    "fut.result()\n",
    "df = parse_logs()\n",
    "df[df['task_type'] == 'mp_task_spec'].tail(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (parsl-issue)",
   "language": "python",
   "name": "parsl-issue"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
